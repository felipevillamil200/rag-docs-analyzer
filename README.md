Â¡Excelente Felipe! ğŸ™Œ
Ya que tu proyecto ahora **sÃ­ incluye anÃ¡lisis automÃ¡tico de contratos + generaciÃ³n de reportes en PDF + mejoras visuales en Gradio**, actualicÃ© tu README para que refleje todas estas capacidades reales (y no quede como â€œfuturoâ€ solamente).

---

## ğŸ“„ README.md actualizado

```markdown
# ğŸ“‘ Chatbot RAG con Cerebras + Chroma + Gradio

Este proyecto implementa un **chatbot de RecuperaciÃ³n Aumentada con GeneraciÃ³n (RAG)** que permite:

- Subir documentos en **PDF o DOCX**.
- **Extraer e indexar** el contenido en una base de datos vectorial (**Chroma**).
- Consultar los documentos en lenguaje natural.
- Obtener respuestas contextualizadas usando un **LLM de Cerebras**.
- Generar **resÃºmenes automÃ¡ticos** de documentos.
- Realizar **anÃ¡lisis automÃ¡tico de contratos** (partes, monto, duraciÃ³n, jurisdicciÃ³n, clÃ¡usula de terminaciÃ³n).
- Exportar resultados en **reportes PDF profesionales** usando `reportlab`.

---

## ğŸš€ TecnologÃ­as utilizadas
- **LLM**: [Cerebras](https://inference.cerebras.net/) (API Key requerida).
- **Vector DB**: [Chroma](https://www.trychroma.com/) (open-source, corre localmente).
- **Framework RAG**: [LangChain](https://www.langchain.com/).
- **Procesamiento de documentos**: 
  - [PyPDF2](https://pypi.org/project/PyPDF2/) â†’ PDFs.
  - [python-docx](https://pypi.org/project/python-docx/) â†’ Word.
- **Interfaz de usuario**: [Gradio](https://www.gradio.app/).
- **Reportes**: [pandas](https://pandas.pydata.org/) + [reportlab](https://www.reportlab.com/).

---

## ğŸ“‚ Estructura del proyecto

```

llm-rag-project/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ **init**.py
â”‚   â”œâ”€â”€ main.py              # Interfaz con Gradio
â”‚   â”œâ”€â”€ document_loader.py   # Extraer texto de PDF/DOCX
â”‚   â”œâ”€â”€ vector_store.py      # Manejo de Chroma (indexar/consultar)
â”‚   â””â”€â”€ rag_pipeline.py      # ConexiÃ³n Chroma + Cerebras (RAG)
â”‚
â”œâ”€â”€ data/                    # Carpeta para documentos de prueba
â”‚   â”œâ”€â”€ contrato_alquiler.pdf
â”‚   â””â”€â”€ acuerdo_confidencialidad.docx
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env                     # Clave de API (no subir a GitHub)

````

---

## ğŸ”‘ ConfiguraciÃ³n de variables de entorno

Crea un archivo `.env` en la raÃ­z del proyecto con tu API Key de **Cerebras**:

```env
CEREBRAS_API_KEY=tu_api_key_aqui
````

---

## âš™ï¸ InstalaciÃ³n y ejecuciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tuusuario/llm-rag-project.git
cd llm-rag-project
```

### 2. Crear y activar un entorno virtual

```bash
python -m venv venv
.\venv\Scripts\activate   # Windows
# o
source venv/bin/activate  # Linux/Mac
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Ejecutar la app

```bash
python -m app.main
```

### 5. Abrir en navegador

Gradio se levantarÃ¡ en:

```
http://127.0.0.1:7860
```

---

## ğŸ§ª Uso

### ğŸ”¹ QA sobre documentos

1. Sube un documento PDF o DOCX.
2. Haz clic en **Indexar documento**.
3. Escribe una pregunta en lenguaje natural.
4. Recibe una respuesta contextualizada generada por **Cerebras + RAG**.

### ğŸ”¹ Resumen automÃ¡tico

* Haz clic en **Generar resumen** â†’ el sistema devuelve un resumen en 5 puntos clave.

### ğŸ”¹ AnÃ¡lisis de contratos

* Haz clic en **Analizar contrato y generar reporte** â†’ el sistema:

  * Extrae partes, monto, duraciÃ³n, jurisdicciÃ³n y clÃ¡usula de terminaciÃ³n.
  * Muestra los resultados en una tabla interactiva.
  * Genera un **reporte PDF profesional**.

---

## ğŸ“Œ PrÃ³ximos pasos

* [ ] Permitir carga de **mÃºltiples documentos** en la misma sesiÃ³n.
* [ ] Agregar mÃ³dulo de **evaluaciÃ³n automÃ¡tica de respuestas** (precisiÃ³n/relevancia).
* [ ] Exponer la soluciÃ³n como **API REST (FastAPI)**.
* [ ] Desplegar en **Hugging Face Spaces** para demo pÃºblica.

---

## âš ï¸ Notas

* Archivo `.env` a GitHub (Colocar tu API Key).
* Si quieres usar otro modelo distinto de Cerebras (ej: OpenAI, Hugging Face), puedes reemplazarlo en `rag_pipeline.py`.

---

## âœ¨ Autor

Proyecto desarrollado por **Felipe** como portafolio para vacantes en IA Generativa.

```

---


